# Configuration file for paper `How to backdoor federated learning`

num_clients: 100 # 100
num_selected_clients: 40
num_malicious_clients: 3
global_learning_rate: -1

num_rounds: 100000
batch_size: 64
num_epochs: 1
optimizer: SGD
learning_rate: 0.1
lr_decay: boundaries
decay_boundaries: [23400,62400,93600]
decay_values: [1.0,0.1,0.01,0.001]
model_name: resnet18
augment_data: true
save_updates: false
dataset: cifar10
data_distribution: dirichlet
workers: 1

attack_type: model_replacement
backdoor_type: semantic
backdoor_feature_aux_train: [389,561,874,1605,3378,3678,4528,9744,19165,19500,21422,22984,32941,34287,34385,36005,37365,37533,38658,38735,39824,40138,47026,48003,48030,49163,49588]
backdoor_feature_aux_test: [41336,41861,47001]
backdoor_feature_target: 2
backdoor_feature_remove_malicious: true
backdoor_feature_augment_times: 200

mal_learning_rate: 0.01
mal_decay_rate: 1.0
mal_decay_steps: 5
mal_num_epochs: 6
mal_step_learning_rate: true
mal_num_batch: 9
poison_samples: 20

scale_attack: True
scale_attack_weight: 40

attack_frequency: 1.0