
base_experiment: # the base config object  
  environment:
    num_clients: 48
    num_selected_clients: 48
    num_malicious_clients: 0
    experiment_name: "cifar_clients"
    use_config_dir: true
  server:
    num_rounds: 1000
    num_test_batches: 25
    aggregator:
      name: FedAvg
    global_learning_rate: 1.0
    intrinsic_dimension: 12000
  client:
    model_name: lenet5_intrinsic
    num_params: 12000
    model_init_path: "/home/ubuntu/rofl-project-code/models/cifar_lenet5_intrinsic_12k.txt"
    quantization:
      type: probabilistic
      bits: 8
      frac: 7
    benign_training:
      num_epochs: 2
      batch_size: 64
      optimizer: SGD
      learning_rate: $VARIES$
  dataset:
    dataset: cifar10
    data_distribution: IID
    augment_data: true
  job:
    minutes: 240 # Max. minutes to run. Leonhard has 240 and 1440 queues
    cpu_cores: 20
    cpu_mem_per_core: 4096
    use_gpu: 1
    gpu_memory_min: 10240
  crypto:
    enc_type: Plain #l2, Range, Plain
    fp_bits: 16
    fp_frac: 7
    value_range: 8
    n_partition: 64
    l2_value_range: 32
    check_percentage: 1.0
  e2e:
    client_machines: 4 # is this correct?
    speculative_execution: $VARIES$

experiments: # in the experiments object you have a list for the different experiments with the values for the fields marked as $VARIES$ in the base config object.

# We have
  # plain, quantized, and rsl


- client: # plain
    benign_training:
      learning_rate: 0.5
- client: # plain
    benign_training:
      learning_rate: 0.4
- client: # plain
    benign_training:
      learning_rate: 0.28

- client: # plain
    benign_training:
      learning_rate: 0.24
- client: # plain
    benign_training:
      learning_rate: 0.2

- client: # plain
    benign_training:
      learning_rate: 0.18
- client: # plain
    benign_training:
      learning_rate: 0.14
- client: # plain
    benign_training:
      learning_rate: 0.1
- client: # plain
    benign_training:
      learning_rate: 0.08
