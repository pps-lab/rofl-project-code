
base_experiment: # the base config object  
  environment:
    num_clients: 48
    num_selected_clients: 48
    num_malicious_clients: 0
    experiment_name: "cifar_clients"
    use_config_dir: true
  server:
    num_rounds: 400
    num_test_batches: 25
    aggregator:
      name: FedAvg
    global_learning_rate: 1.0
  client:
    model_name: stacked_lstm
    model_init_path: "/home/ubuntu/rofl-project-code/models/mobilenet.txt"
    benign_training:
      num_epochs: 1
      batch_size: 64
      optimizer: SGD
      learning_rate: 0.5
    num_params: 700458
    quantization: ~
  dataset:
    dataset: shakespeare
    data_distribution: IID
    augment_data: false
  job:
    minutes: 240 # Max. minutes to run. Leonhard has 240 and 1440 queues
    cpu_cores: 20
    cpu_mem_per_core: 4096
    use_gpu: 1
    gpu_memory_min: 10240
  crypto:
    enc_type: $VARIES #l2, Range, Plain
    value_range: 8
    n_partition: 64
    l2_value_range: 32
    check_percentage: 0.013 # 0-100 for Range, # 3652 , 1.331 %
    fp_bits: 16
    fp_frac: 7
  e2e:
    client_machines: 4 # is this correct?
    speculative_execution: $VARIES$

experiments: # in the experiments object you have a list for the different experiments with the values for the fields marked as $VARIES$ in the base config object.
- client: # plain
    benign_training:
      learning_rate: 0.1
- client: # plain
    benign_training:
      learning_rate: 0.5
- client: # plain
    benign_training:
      learning_rate: 1.0