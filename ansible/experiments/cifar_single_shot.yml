
## WE ENABLED DATA AUG FOR THE EDGE CASES BECAUSE IT SEEMS TO WORK BETTER

base_experiment: # the base config object  
  environment:
    num_clients: 100
    num_selected_clients: 40
    num_malicious_clients: 1
    experiment_name: "cifar_bounds"
    use_config_dir: true
    attack_frequency: 1.0
    load_model: ./models/resnet18.h5
    attacker_full_knowledge: true
    attacker_full_dataset: true
  server:
    num_rounds: 50
    num_test_batches: 50
    aggregator:
      name: FedAvg
    global_learning_rate: 1
  client:
    model_name: resnet18
    clip: ~
    benign_training:
      num_epochs: 2
      batch_size: 64
      optimizer: SGD
      learning_rate: 0.02
    malicious:
      attack_start: 5
      attack_stop: 5
      objective:
        name: TargetedAttack
        args:
          num_epochs: 6
          num_batch: 10
          poison_samples: 20
          optimizer: SGD
          learning_rate: 0.1
          step_decay: true
      backdoor:
        type: semantic
        train: $VARIES$
        test: $VARIES$
        target_label: 2
        remove_from_benign_dataset: true
        augment_times: 200
        augment_data: true
      evasion:
        name: NormBoundPGDEvasion
        args:
          norm_type: l2
          pgd_factor: ~
          scale_factor: 100
  dataset:
    dataset: cifar10
    data_distribution: dirichlet
    augment_data: true # for training
  job:
    minutes: 90 # Max. minutes to run. Leonhard has 240 and 1440 queues
    cpu_cores: 20
    cpu_mem_per_core: 4096
    use_gpu: 1
    gpu_memory_min: 10240

experiments: # in the experiments object you have a list for the different experiments with the values for the fields marked as $VARIES$ in the base config object.
#- client: # bgwall
#    malicious:
#      objective:
#        args:
#          num_epochs: 6
#          step_decay: true
#          poison_samples: 16
#          learning_rate: 0.05
#      backdoor:
#        train: [568,3934,12336,30560,33105,33615,33907,36848,41706] # bgwall
#        test: [330, 30696, 40713]
#- client: # rstripe
#    malicious:
#      objective:
#        args:
#          num_epochs: 6
#          step_decay: true
#          poison_samples: 16
#          learning_rate: 0.05
#      backdoor:
#        train: [ 2180,2771,3233,4932,6241,6813,6869,9476,11395,11744,14209,14238,18716,19793,20781,21529,31311,40518,40633,42119,42663,49392 ]
#        test: [ 42119,42663,49392 ]

- client: # greencar
    malicious:
      backdoor:
        train: [389,561,874,41861,3378,3678,4528,9744,19165,19500,21422,22984,32941,34287,34385,36005,37365,37533,38658,38735,39824,40138,47026,48003,48030,49163,49588]
        test: [41336,1605,47001]

- client: # edge
    malicious:
      backdoor:
        remove_from_benign_dataset: false
        type: edge
        edge_case_type: NorthWesternEdgeCase
        augment_data: true
        augment_times: 50

- client: # edge
    malicious:
      backdoor:
        remove_from_benign_dataset: false
        type: edge
        edge_case_type: CifarRandomNoiseEdgeCase
        augment_data: true
        augment_times: 50

### Add bounded versions here
#- client: # bgwall
#    clip:
#      type: l2
#      value: 5.0
#    malicious:
#      objective:
#        args:
#          num_epochs: 6
#          step_decay: true
#          poison_samples: 20
#          learning_rate: 0.05
#      backdoor:
#        train: [568,3934,12336,30560,33105,33615,33907,36848,41706] # bgwall
#        test: [330, 30696, 40713]
#      evasion:
#        args:
#          pgd_factor: 0.0625
#- client: # rstripe
#    clip:
#      type: l2
#      value: 5.0
#    malicious:
#      objective:
#        args:
#          num_epochs: 6
#          step_decay: true
#          poison_samples: 20
#          learning_rate: 0.05
#      backdoor:
#        train: [ 2180,2771,3233,4932,6241,6813,6869,9476,11395,11744,14209,14238,18716,19793,20781,21529,31311,40518,40633,42119,42663,49392 ]
#        test: [ 42119,42663,49392 ]
#      evasion:
#        args:
#          pgd_factor: 0.0625
#
- client: # greencar
    clip:
      type: l2
      value: 5.0
    malicious:
      backdoor:
        train: [389,561,874,41861,3378,3678,4528,9744,19165,19500,21422,22984,32941,34287,34385,36005,37365,37533,38658,38735,39824,40138,47026,48003,48030,49163,49588]
        test: [41336,1605,47001]
      evasion:
        args:
          pgd_factor: 0.0625


- client: # edge
    clip:
      type: l2
      value: 5.0
    malicious:
      backdoor:
        remove_from_benign_dataset: false
        type: edge
        edge_case_type: NorthWesternEdgeCase
        augment_data: true
        augment_times: 50
      evasion:
        args:
          pgd_factor: 0.0625

- client: # edge
    clip:
      type: l2
      value: 5.0
    malicious:
      backdoor:
        remove_from_benign_dataset: false
        type: edge
        edge_case_type: CifarRandomNoiseEdgeCase
        augment_data: true
        augment_times: 50
      evasion:
        args:
          pgd_factor: 0.0625
#
#- client: # bgwall
#    clip:
#      type: median_l2
#      value: 2.0
#    malicious:
#      objective:
#        args:
#          num_epochs: 20
#          step_decay: true
#          poison_samples: 16
#          learning_rate: 0.05
#      backdoor:
#        train: [568,3934,12336,30560,33105,33615,33907,36848,41706] # bgwall
#        test: [330, 30696, 40713]
#      evasion:
#        args:
#          pgd_factor: 2.0
#          norm_type: median_l2